{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "# Jupyter notebook for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "# Copied from `train` function in train_simple.py:L78\n",
        "import yaml\n",
        "\n",
        "device = 'cpu'\n",
        "hyp = 'data/hyps/hyp.scratch-low.yaml'\n",
        "\n",
        "with open(hyp, errors=\"ignore\") as f:\n",
        "    hyp = yaml.safe_load(f)  # load hyps dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.yolo import Model\n",
        "from utils.general import check_dataset\n",
        "\n",
        "cfg = 'models/yolov5n_kaist-rgbt.yaml'\n",
        "# cfg = 'models/yolov5s_kaist-rgbt_anchor.yaml'\n",
        "# cfg = 'models/yolov5s_kaist-rgbt_rev.yaml'\n",
        "data = 'data/kaist-rgbt.yaml'\n",
        "data_dict = check_dataset(data)\n",
        "\n",
        "nc = int(data_dict[\"nc\"])  # number of classes\n",
        "model = Model(cfg, ch=3, nc=nc, anchors=hyp.get(\"anchors\")).to(device)  # create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "anchors = model.model[-1].anchors\n",
        "\n",
        "# [TODO] Draw anchors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'model' is your YOLOv5 model\n",
        "anchors = model.model[-1].anchors.cpu().detach().numpy()\n",
        "\n",
        "# Visualize anchors\n",
        "import numpy as np\n",
        "def plot_anchors(anchors, image_shape=(640, 512)):\n",
        "    fig, ax = plt.subplots(1)\n",
        "    img = np.ones(image_shape) * 255  # white background\n",
        "    ax.imshow(img, extent=[0, image_shape[1], image_shape[0], 0], cmap='gray')\n",
        "\n",
        "    grid_size = 80  # Adjust grid size if necessary\n",
        "    for i, anchor in enumerate(anchors):\n",
        "        for j in range(anchor.shape[0]):\n",
        "            w, h = anchor[j]\n",
        "            rect = plt.Rectangle(\n",
        "                ((image_shape[1] - w) / 2, (image_shape[0] - h) / 2), w, h,\n",
        "                linewidth=2, edgecolor='red', facecolor='none', linestyle='--'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            # ax.text(\n",
        "            #     ((image_shape[1] - w) / 2), ((image_shape[0] - h) / 2) - 10,\n",
        "            #     f'Anchor {i+1},{j+1}: [{w:.1f}, {h:.1f}]',\n",
        "            #     color='red', fontsize=10, ha='left'\n",
        "            # )\n",
        "\n",
        "    plt.title(\"YOLOv5 Anchors\")\n",
        "    plt.xlabel(\"Width\")\n",
        "    plt.ylabel(\"Height\")\n",
        "    plt.ylim(310,330)\n",
        "    plt.xlim(246,266)\n",
        "    plt.show()\n",
        "\n",
        "plot_anchors(anchors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 레이블 파일 경로 목록 가져오기\n",
        "label_files = [os.path.join('datasets/kaist-rgbt/train/labels', f) for f in \\\n",
        "               os.listdir('datasets/kaist-rgbt/train/labels') if os.path.isfile(os.path.join('datasets/kaist-rgbt/train/labels', f))]\n",
        "\n",
        "# 바운딩 박스 크기 수집\n",
        "bboxes = []\n",
        "for file in label_files:\n",
        "    with open(file, 'r') as fp:\n",
        "        labels = [x.split() for x in fp.read().strip().splitlines() if len(x)]\n",
        "    if len(labels):\n",
        "        labels = np.array(labels, dtype=np.float32)\n",
        "        widths = labels[:, 3]\n",
        "        heights = labels[:, 4]\n",
        "        bboxes.extend(zip(widths, heights))\n",
        "\n",
        "# numpy 배열로 변환\n",
        "bboxes = np.array(bboxes)\n",
        "\n",
        "# K-means clustering without sklearn\n",
        "def kmeans(data, k, max_iters=100):\n",
        "    centroids = data[np.random.choice(data.shape[0], k, replace=False)]\n",
        "    for _ in range(max_iters):\n",
        "        distances = np.sqrt(((data - centroids[:, np.newaxis])**2).sum(axis=2))\n",
        "        closest = np.argmin(distances, axis=0)\n",
        "        new_centroids = np.array([data[closest == i].mean(axis=0) for i in range(k)])\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "    return centroids\n",
        "\n",
        "# 최적 anchor 계산 (k-means clustering 사용)\n",
        "clustering_anchors = kmeans(bboxes, k=9)\n",
        "# 픽셀 단위로 변환\n",
        "pixel_anchors = clustering_anchors * np.array([640, 512])\n",
        "pixel_anchors = pixel_anchors[np.argsort(pixel_anchors[:,0])]\n",
        "print(\"Kmeans Anchors\\n\",pixel_anchors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check: dataset\n",
        "- Read images and label\n",
        "- Visualize bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "annFile = 'datasets/kaist-rgbt/train/labels/set05_V000_I01219.txt'\n",
        "lwirFile = annFile.replace('labels', 'images/lwir').replace('.txt', '.jpg')\n",
        "visFile  = annFile.replace('labels', 'images/visible').replace('.txt', '.jpg')\n",
        "\n",
        "# Read images\n",
        "img_lwir = cv2.imread(lwirFile)\n",
        "img_vis  = cv2.imread(visFile)\n",
        "\n",
        "h, w = img_vis.shape[:2]\n",
        "\n",
        "# Read labels\n",
        "with open(annFile, 'r') as fp:\n",
        "    labels = [x.split() for x in fp.read().strip().splitlines() if len(x)]\n",
        "\n",
        "colors = {\n",
        "    0: (255, 0, 0),\n",
        "    1: (0, 255, 0),\n",
        "    2: (0, 0, 255),\n",
        "    3: (255, 0, 255),\n",
        "}\n",
        "\n",
        "if len(labels):\n",
        "    # convert normalized bbox to pixel coordinates\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    labels[:, (1, 3)] *= w\n",
        "    labels[:, (2, 4)] *= h\n",
        "\n",
        "    cls = labels[:, 0]\n",
        "\n",
        "    xyxy = np.zeros((len(labels), 4))\n",
        "    xyxy[:, :2] = labels[:, 1:3]\n",
        "    xyxy[:, 2:] = labels[:, 1:3] + labels[:, 3:5]\n",
        "    xyxy = xyxy.astype(np.int16)\n",
        "\n",
        "    for c, bb in zip(cls, xyxy):\n",
        "        color = colors[c]\n",
        "        cv2.rectangle(img_lwir, bb[:2], bb[2:], color)\n",
        "        cv2.rectangle(img_vis,  bb[:2], bb[2:], color)\n",
        "\n",
        "images = np.concatenate([img_lwir, img_vis], axis=1)\n",
        "Image.fromarray(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check: dataset class\n",
        "- Visualize bounding boxes from dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.dataloaders import create_dataloader\n",
        "from utils.general import check_img_size, colorstr\n",
        "\n",
        "imgsz = 640\n",
        "batch_size = 1\n",
        "single_cls = False\n",
        "seed = 0\n",
        "\n",
        "train_path = data_dict[\"train\"]\n",
        "gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "imgsz = check_img_size(imgsz, gs, floor=gs * 2)  # verify imgsz is gs-multiple\n",
        "\n",
        "train_loader, dataset = create_dataloader(\n",
        "    train_path,\n",
        "    imgsz,\n",
        "    batch_size,\n",
        "    gs,\n",
        "    single_cls,\n",
        "    hyp=hyp,\n",
        "    augment=True,      # TODO: check if there is no bug when applying augmentation\n",
        "    cache=None,\n",
        "    rect=False,\n",
        "    rank=-1,\n",
        "    workers=8,\n",
        "    image_weights=False,\n",
        "    quad=False,\n",
        "    prefix=colorstr(\"train: \"),\n",
        "    shuffle=False,      # No shuffle for debugging\n",
        "    seed=seed,\n",
        "    rgbt_input=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.dataloaders import LoadRGBTImagesAndLabels\n",
        "from utils.general import xywh2xyxy\n",
        "\n",
        "frame = 103\n",
        "\n",
        "# Get a minibatch\n",
        "# for ii, (imgs, targets, paths, _) in enumerate(train_loader):\n",
        "#     break\n",
        "\n",
        "# Get a minibatch (fast)\n",
        "imgs, targets, paths, shapes, _ = LoadRGBTImagesAndLabels.collate_fn([dataset[frame]])\n",
        "\n",
        "idx = 0\n",
        "img_lwir = imgs[0][idx].numpy().transpose((1, 2, 0))\n",
        "img_vis  = imgs[1][idx].numpy().transpose((1, 2, 0))\n",
        "h, w = img_vis.shape[:2]\n",
        "\n",
        "labels = targets.numpy()\n",
        "\n",
        "colors = {\n",
        "    0: (255, 0, 0), #r \n",
        "    1: (0, 255, 0), #g\n",
        "    2: (0, 0, 255), #b\n",
        "    3: (255, 0, 255),\n",
        "}\n",
        "\n",
        "if len(labels):\n",
        "    labels = labels[labels[:, 0] == idx, 1:]\n",
        "\n",
        "    # convert normalized bbox to pixel coordinates\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    labels[:, (1, 3)] *= w\n",
        "    labels[:, (2, 4)] *= h\n",
        "\n",
        "    cls = labels[:, 0]\n",
        "\n",
        "    xyxy = xywh2xyxy(labels[:, 1:5])\n",
        "    xyxy = xyxy.astype(np.int16)\n",
        "\n",
        "    img_lwir = np.ascontiguousarray(img_lwir)\n",
        "    img_vis = np.ascontiguousarray(img_vis)\n",
        "\n",
        "    for c, bb in zip(cls, xyxy):\n",
        "        color = colors[c]\n",
        "        cv2.rectangle(img_lwir, bb[:2], bb[2:], color)\n",
        "        cv2.rectangle(img_vis,  bb[:2], bb[2:], color)\n",
        "\n",
        "images = np.concatenate([img_lwir, img_vis], axis=1)\n",
        "print(paths[idx])\n",
        "Image.fromarray(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run trained model\n",
        "- Visualize bounding boxes from dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from models.yolo import Model\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "weights = 'runs/train/yolov5n-rgbt3/weights/best.pt'      # Train your own model!\n",
        "data = 'data/kaist-rgbt.yaml'\n",
        "cfg = 'models/yolov5s_kaist-rgbt.yaml'\n",
        "hyp = 'data/hyps/hyp.scratch-low.yaml'\n",
        "nc = 1\n",
        "half = False  # use FP16 half-precision inference\n",
        "dnn = False  # use OpenCV DNN for ONNX inference\n",
        "device = select_device('cpu')\n",
        "\n",
        "with open(hyp, errors=\"ignore\") as f:\n",
        "    hyp = yaml.safe_load(f)  # load hyps dict\n",
        "\n",
        "model = Model(cfg, ch=3, nc=nc, anchors=hyp.get(\"anchors\")).to(device)  # create\n",
        "\n",
        "# inference\n",
        "model.eval()\n",
        "ims = [im.to(device, non_blocking=True).float() / 255 for im in imgs]    # For RGB-T input\n",
        "with torch.no_grad():\n",
        "    pred = model(ims)  # forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from utils.general import scale_boxes, non_max_suppression\n",
        "\n",
        "conf_thres = 0.25  # confidence threshold\n",
        "iou_thres = 0.45  # NMS IOU threshold\n",
        "max_det = 1000  # maximum detections per image\n",
        "classes = None\n",
        "agnostic_nms = False  # class-agnostic NMS\n",
        "\n",
        "pred1 = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.general import scale_boxes, non_max_suppression\n",
        "\n",
        "conf_thres = 0.25  # confidence threshold\n",
        "iou_thres = 0.45  # NMS IOU threshold\n",
        "max_det = 1000  # maximum detections per image\n",
        "classes = None\n",
        "agnostic_nms = False  # class-agnostic NMS\n",
        "\n",
        "pred1 = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "\n",
        "# Resize predicted box\n",
        "scale_boxes()         # see valpy:L285\n",
        "\n",
        "# [TODO] draw predictions (see detect.py:L178)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
